{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You shall know a word by the company it keeps\n",
    ">\n",
    "> *John Rudolf Firth, 1957*\n",
    "\n",
    "This concept was used to learn numerical representation for words. Simply assigning a random unique numerical code to each word does not capture similarities and differences between different words, and does not allow you to use common information between for example `cats` and `dogs` in a pet context.\n",
    "\n",
    "However, one could try to capture each word by a list of numbers, for example:\n",
    "\n",
    "`[0.5, 0.26, -0.213, 0.76]`\n",
    "\n",
    "The first number could indicate whether the word is more materialistic of more conceptual, the second whether it s a verb or not, the third wheter it's an animal, or whether it is furry, etc. Of course 4 numbers are not enough, but no worries, modern computers can handle a bit more than $4$ numbers.\n",
    "\n",
    "The concept is cute, but how would one define these numbers? Well, by the company of the words! If you have a lot of sentences, you can look at windows of for example 5 adjacent words. For example, if you have\n",
    "\n",
    "`The grey cat has fluffy hair and drinks milk` has these windows:\n",
    "\n",
    "* the, grey, **cat**, has, fluffy\n",
    "* grey, cat, **has**, fluffy, hair\n",
    "* cat, has, **fluffy**, hair, and\n",
    "* has, fluffy, **hair**, and, drinks\n",
    "* fluffy, hair, **and**, drinks, milk\n",
    "\n",
    "The middle word is bold on purpose, this word is kept company by two other words on both sides. With a so called *neural network* one could try to predict the middle word on the basis of the accompanying four words. Of course, this is ill-defined. In the middle of $4$ words, there are often multiple words that fit:\n",
    "\n",
    "* the, grey, **cat**, has, fluffy\n",
    "* the, grey, **dog**, has, fluffy\n",
    "* the, grey, **bird**, has, fluffy\n",
    "\n",
    "However\n",
    "\n",
    "* the, grey, **snake**, has, fluffy\n",
    "\n",
    "makes less sense, and in general will not occur in a corpus, for example in all text from Wikipedia.\n",
    "\n",
    "\n",
    "For the network to perform well, it will learn some similar features for cat, dogs and birds, but not for snakes. If you then train the network on for example wikipedia, or any other corpus of a language, the numerical representations will make sense. In general the numerical representation consists of several thousand of numbers.\n",
    "\n",
    "Lets use gensim, and see what happens.\n",
    "\n",
    "Run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the scentences from the previous exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "with open('poems.txt', 'r') as poems_file:\n",
    "    for line in poems_file:\n",
    "        sentence = line.strip().lower().split()\n",
    "        if ''.join(sentence) != '':\n",
    "            sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then create a model an train it on these sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(size=64, window=5, min_count=5)\n",
    "\n",
    "model.build_vocab(sentences)\n",
    "model.train(sentences, total_examples=len(sentences), epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the 64 numbers that represent **\"heart\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model['heart']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of sentences is way to small to create a decent model of the words, one needs at least 100 sentences per word. Stanford's NLP Group published some decent wordvectors based on 2 billion tweets. Let's load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about 2 minutes.\n",
    "\n",
    "stanford_model = KeyedVectors.load_word2vec_format('glove.6B.100d.bin', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that this is done, lets find out what **queen - woman + man** evaluates to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanford_model.most_similar(positive=['queen', 'man'], negative=['woman'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about **walking - aiming + aim**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanford_model.most_similar(positive=['walking', 'aim'], negative=['aiming'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise\n",
    "\n",
    "As an exercise, compute **France - Netherlands + Amsterdam**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: One line of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some words seem to make sense, but that's probably just randomness anyway."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
